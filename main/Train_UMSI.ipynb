{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/wang/.conda-envs/tf-cuda9/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/projects/wang/.conda-envs/tf-cuda9/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/projects/wang/.conda-envs/tf-cuda9/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/projects/wang/.conda-envs/tf-cuda9/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/projects/wang/.conda-envs/tf-cuda9/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/projects/wang/.conda-envs/tf-cuda9/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/projects/wang/.conda-envs/tf-cuda9/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/projects/wang/.conda-envs/tf-cuda9/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/projects/wang/.conda-envs/tf-cuda9/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/projects/wang/.conda-envs/tf-cuda9/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/projects/wang/.conda-envs/tf-cuda9/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/projects/wang/.conda-envs/tf-cuda9/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "import cv2\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "import tqdm\n",
    "import math, random\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_loading import load_datasets_singleduration\n",
    "from util import get_model_by_name, create_losses\n",
    "\n",
    "from losses_keras2 import *\n",
    "from sal_imp_utilities import *\n",
    "from cb import InteractivePlot\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check GPU status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 10:34:23 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB            Off| 00000000:1A:00.0 Off |                    0 |\n",
      "| N/A   32C    P0               55W / 300W|  17515MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB            Off| 00000000:1B:00.0 Off |                    0 |\n",
      "| N/A   38C    P0               56W / 300W|  10991MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2-32GB            Off| 00000000:3D:00.0 Off |                    0 |\n",
      "| N/A   46C    P0               61W / 300W|  21981MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2-32GB            Off| 00000000:3E:00.0 Off |                    0 |\n",
      "| N/A   54C    P0              186W / 300W|   5185MiB / 32768MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2-32GB            Off| 00000000:88:00.0 Off |                    0 |\n",
      "| N/A   31C    P0               43W / 300W|      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2-32GB            Off| 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   34C    P0               43W / 300W|      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2-32GB            Off| 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   33C    P0               44W / 300W|      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2-32GB            Off| 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   31C    P0               43W / 300W|      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      7499      C   ...rcooked-mep_tom_act_strat-S2@mattbt    17512MiB |\n",
      "|    1   N/A  N/A    501735      C   ...-Overcooked-mep_tom_strat-S2@mattbt    10988MiB |\n",
      "|    2   N/A  N/A   3286623      C   ...-Overcooked-hsp_tom_strat-S2@mattbt    10988MiB |\n",
      "|    2   N/A  N/A   3289674      C   ...rcooked-mep_tom_act_strat-S2@mattbt    10990MiB |\n",
      "|    3   N/A  N/A    417562      C   python                                     5182MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THESE IN \n",
    "bp = \"/projects/wang/datasets/\"\n",
    "\n",
    "dataset_imp = \"SalChartQA\"\n",
    "dataset_sal = \"UMSI_SALICON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SalChartQA\n",
      "Length of loaded files:\n",
      "train images: 2113\n",
      "train maps: 2113\n",
      "val images: 595\n",
      "val maps: 595\n"
     ]
    }
   ],
   "source": [
    "data_imp = load_datasets_singleduration(dataset_imp, bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SALICON (no fixation coords)\n",
      "Length of loaded files:\n",
      "train images: 10000\n",
      "train maps: 10000\n",
      "val images: 5000\n",
      "val maps: 5000\n",
      "test images 5000\n",
      "Length of loaded files:\n",
      "train images: 10000\n",
      "train maps: 10000\n",
      "val images: 5000\n",
      "val maps: 5000\n"
     ]
    }
   ],
   "source": [
    "data_sal = load_datasets_singleduration(dataset_sal, bp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_savedir = \"ckpt\"\n",
    "\n",
    "# FILL THESE IN: set training parameters\n",
    "# If you want to resume from previous training, set load_weights = True\n",
    "load_weights = False\n",
    "weightspath = \"./ckpt/weights.hdf5\"\n",
    "\n",
    "batch_size = 4\n",
    "init_lr = 0.0001\n",
    "lr_reduce_by = .1\n",
    "reduce_at_epoch = 3\n",
    "n_epochs = 15\n",
    "\n",
    "opt = Adam(lr=init_lr) \n",
    "\n",
    "model_name = \"UMSI\"\n",
    "model_inp_size = (240, 320)\n",
    "model_out_size = (480, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = model_inp_size + (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /projects/wang/.conda-envs/tf-cuda9/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "xception output shapes: (?, 30, 40, 2048)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'filters' and 'kernel_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-085de5570208>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/wang/projects/UMSI/src/singleduration_models.py\u001b[0m in \u001b[0;36mUMSI\u001b[0;34m(input_shape, conv_filters, verbose, print_shapes, n_outs, ups, freeze_enc, return_sequences)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;31m# ASPP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;31m# TODO: Fill the missing parameters in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0mc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"aspp_csep0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m     \u001b[0mc6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDepthwiseConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"aspp_csepd6_depthwise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0mc12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDepthwiseConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"aspp_csepd12_depthwise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/wang/.conda-envs/tf-cuda9/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'filters' and 'kernel_size'"
     ]
    }
   ],
   "source": [
    "# get model \n",
    "model_params = {\n",
    "    'input_shape': input_shape,\n",
    "    'n_outs': 2\n",
    "}\n",
    "model_func, mode = get_model_by_name(model_name)\n",
    "model = model_func(**model_params)\n",
    "\n",
    "if load_weights: \n",
    "    model.load_weights(weightspath)\n",
    "    print(\"load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data generation and checkpoints\n",
    "if not os.path.exists(ckpt_savedir): \n",
    "    os.makedirs(ckpt_savedir)\n",
    "\n",
    "# Generators\n",
    "gen_train = ImpAndClassifGenerator(\n",
    "        img_filenames=data_imp[0],\n",
    "        imp_filenames=data_imp[1],\n",
    "        fix_filenames=None,\n",
    "        extra_imgs=data_sal[0], # For feeding a much larger dataset, e.g. salicon, that the generator will subsample to maintain class balance\n",
    "        extra_imps=data_sal[1],\n",
    "        extra_fixs=None,\n",
    "        extras_per_epoch=160,\n",
    "        batch_size=4,\n",
    "        img_size=(shape_r,shape_c),\n",
    "        map_size=(shape_r_out, shape_c_out),\n",
    "        shuffle=True,\n",
    "        augment=False,\n",
    "        n_output_maps=1,\n",
    "        concat_fix_and_maps=False,\n",
    "        fix_as_mat=False,\n",
    "        fix_key=\"\",\n",
    "        str2label=None,\n",
    "        dummy_labels=False,\n",
    "        num_classes=6,\n",
    "        pad_imgs=True,\n",
    "        pad_maps=True,\n",
    "        return_names=False,\n",
    "        return_labels=True,\n",
    "        read_npy=False)\n",
    "\n",
    "gen_val = ImpAndClassifGenerator(\n",
    "            img_filenames=data_imp[3], \n",
    "            imp_filenames=data_imp[4], \n",
    "            fix_filenames=None, \n",
    "            extra_imgs=data_sal[3], # For feeding a much larger dataset, e.g. salicon, that the generator will subsample to maintain class balance\n",
    "            extra_imps=data_sal[4],\n",
    "            extra_fixs=None,\n",
    "            extras_per_epoch=40,\n",
    "            batch_size=1, \n",
    "            img_size=(shape_r,shape_c), \n",
    "            map_size=(shape_r_out, shape_c_out),\n",
    "            shuffle=False, \n",
    "            augment=False, \n",
    "            str2label=None,\n",
    "            dummy_labels=False,\n",
    "            #n_output_maps=1,\n",
    "        )\n",
    "\n",
    "# Callbacks\n",
    "\n",
    "# where to save checkpoints\n",
    "filepath = os.path.join(ckpt_savedir, dataset_imp + '_kl+cc+bin_ep{epoch:02d}_valloss{val_loss:.4f}.hdf5')\n",
    "\n",
    "print(\"Checkpoints will be saved with format %s\" % filepath)\n",
    "\n",
    "cb_chk = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=True, period=1)\n",
    "cb_plot = InteractivePlot()\n",
    "\n",
    "def step_decay(epoch):\n",
    "    lrate = init_lr * math.pow(lr_reduce_by, math.floor((1+epoch)/reduce_at_epoch))\n",
    "    if epoch%reduce_at_epoch:\n",
    "        print('Reducing lr. New lr is:', lrate)\n",
    "    return lrate\n",
    "cb_sched = LearningRateScheduler(step_decay)\n",
    "\n",
    "cbs = [cb_chk, cb_sched, cb_plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the generator \n",
    "img, outs = gen_train.__getitem__(1)\n",
    "print(\"batch size: %d. Num inputs: %d. Num outputs: %d.\" % (batch_size, len(img), len(outs)))\n",
    "print(outs[0].shape)\n",
    "print(outs[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss={'dec_c_cout': kl_cc_combined, \"out_classif\":\"binary_crossentropy\"}, loss_weights={'dec_c_cout': 1, \"out_classif\":5})\n",
    "\n",
    "print('Ready to train')\n",
    "model.fit_generator(gen_train, epochs=n_epochs, verbose=1, callbacks=cbs, validation_data=gen_val, max_queue_size=10, workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization scripts to check the training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: \n",
    "    W = \"./ckpt/weights.hdf5\"\n",
    "    model.load_weights(W)\n",
    "    print('load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize some output on the val set \n",
    "gen = UMSI_eval_generator(\n",
    "    data_sal[3], \n",
    "    data_sal[4], \n",
    "    inp_size=model_inp_size)\n",
    "\n",
    "examples = [next(gen) for _ in range(50)]\n",
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in examples[4:]:\n",
    "    images, maps, img_filename_= example\n",
    "    preds = model.predict(images[0])\n",
    "    preds_map = preds[0]\n",
    "    preds_classif = preds[1]\n",
    "    break\n",
    "\n",
    "\n",
    "print(\"maps size\", len(maps), maps[0].shape)\n",
    "batch = 0\n",
    "\n",
    "plt.figure(figsize = (14,8))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(reverse_preprocess(np.squeeze(images[0])))\n",
    "\n",
    "plt.title(\"natural images %d\" % batch)\n",
    "\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(maps[0])\n",
    "plt.title('Gt ' )\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(postprocess_predictions(np.squeeze(preds_map[0]),maps[0].shape[0],maps[0].shape[1], zero_to_255=True))\n",
    "plt.title('Prediction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, maps, img_filename= random.choice(examples)\n",
    "\n",
    "print(\"maps size\", len(maps), maps[0].shape)\n",
    "batch = 0\n",
    "preds = model.predict(images[0])\n",
    "preds_map = preds[0]\n",
    "preds_classif = preds[1]\n",
    "cl = np.argmax(preds_classif)\n",
    "print(preds_classif)\n",
    "plt.figure(figsize = (14,8))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(reverse_preprocess(np.squeeze(images[0])))\n",
    "if(cl==0):\n",
    "    plt.title(\"advertisment %d\" % batch)\n",
    "if(cl==1):\n",
    "    plt.title(\"infographic %d\" % batch)\n",
    "if(cl==2):\n",
    "    plt.title(\"movie_posters %d\" % batch)\n",
    "if(cl==3):\n",
    "    plt.title(\"infographics %d\" % batch)\n",
    "if(cl==4):\n",
    "    plt.title(\"webpages %d\" % batch)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(maps[0])\n",
    "plt.title('Gt ' )\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "    # print(\"preds time sahpe\", preds[time].shape)\n",
    "plt.imshow(postprocess_predictions(np.squeeze(preds_map[0]),maps[0].shape[0],maps[0].shape[1], zero_to_255=True))\n",
    "plt.title('Prediction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images, maps, img_filename= random.choice(examples)\n",
    "\n",
    "print(\"maps size\", len(maps), maps[0].shape)\n",
    "batch = 0\n",
    "preds = model.predict(images[0])\n",
    "preds_map = preds[0]\n",
    "preds_classif = preds[1]\n",
    "print(preds_classif)\n",
    "plt.figure(figsize = (14,8))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(reverse_preprocess(np.squeeze(images[0])))\n",
    "plt.title(\"original image %d\" % batch)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(maps[0])\n",
    "plt.title('Gt ' )\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "    # print(\"preds time sahpe\", preds[time].shape)\n",
    "plt.imshow(postprocess_predictions(np.squeeze(preds_map[0]),maps[0].shape[0],maps[0].shape[1], zero_to_255=True))\n",
    "plt.title('Prediction')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = \"./ckpt/imp1k_kl+cc+bin_ep13_valloss-2.4641.hdf5\"\n",
    "model.load_weights(W)\n",
    "print(\"load weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model, test_img, gt_map, inp_size, mode='simple', blur=False,):\n",
    "    # if test_img_base_path is specified, then preserves the original\n",
    "    # nested structure of the directory from which the stuff is pulled\n",
    "    c=0\n",
    "    if blur:\n",
    "        print('BLURRING PREDICTIONS')\n",
    "        if 'blur' not in savedir:\n",
    "            savedir = savedir+'_blur'\n",
    "    else:\n",
    "        print('NOT BLURRING PREDICTIONS')\n",
    "    pre = []\n",
    "    cla = []\n",
    "    maps = []\n",
    "    for i in tqdm.tqdm(range(len(test_img))):\n",
    "        imfile = test_img[i]\n",
    "        heatmap = cv2.imread(gt_map[i], cv2.IMREAD_GRAYSCALE)\n",
    "        batch = 0\n",
    "        time = 0\n",
    "        map_idx = 0\n",
    "        gt_shape = Image.open(imfile).size[::-1]\n",
    "        img = preprocess_images([imfile], inp_size[0], inp_size[1])\n",
    "        preds = model.predict(img)\n",
    "        if mode == 'multistream_concat':\n",
    "            p = preds[time][batch][map_idx][:, :, 0]\n",
    "        elif mode == 'simple':\n",
    "        #Use first two lines when using our own model    \n",
    "            p = preds[0][batch][:,:,0]\n",
    "            classif = preds[1][0]\n",
    "        elif mode == 'singlestream':\n",
    "            p = preds[0][batch][time][:,:,0]\n",
    "        else:\n",
    "            raise ValueError('Unknown mode')\n",
    "        # set zero_to_255 to True when using our own model\n",
    "        p = postprocess_predictions(p, heatmap.shape[0], heatmap.shape[1], blur, normalize=False, zero_to_255=True)\n",
    "        p_norm = (p-np.min(p))/(np.max(p)-np.min(p))\n",
    "        p_img = p_norm*255\n",
    "        hm_img = Image.fromarray(np.uint8(p_img), \"L\")\n",
    "        pre.append(p)\n",
    "        cla.append(classif)\n",
    "        maps.append(heatmap)\n",
    "    return np.array(pre), cla, maps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted maps, predicted classification labels, and the ground truth maps\n",
    "p, p_labels, gt_map = get_prediction(model, data_imp[3], data_imp[4], inp_size=(shape_r, shape_c), mode='simple', blur=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_labels = get_labels(data_sal[3])\n",
    "gt_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import calculate_metrics\n",
    "def get_eval_result(p, gt_map, gt_fix_map=None, gt_fix_points=None, gt_labels=None, p_labels=None):    \n",
    "    #metrics = {\"R2\":[],'RMSE':[],'CC':[],'CC (saliconeval)':[],'KL':[],'SIM':[],'Acc':[],'Acc_per_class':[]}\n",
    "    metrics = {\"R2\":[],'RMSE':[],'CC':[],'CC (saliconeval)':[],'KL':[],'SIM':[],}\n",
    "    for i in range(len(gt_map)):\n",
    "        m = calculate_metrics(p[i], gt_map=gt_map[i], gt_fix_map=None, gt_fix_points=None, gt_labels=None, p_labels=None)\n",
    "        for key in metrics:\n",
    "            if key in m:\n",
    "                metrics[key].append(m[key][0])\n",
    "    for key in metrics:\n",
    "        if key != 'Acc_per_class':\n",
    "            metrics[key] = np.mean(metrics[key])\n",
    "    Acc_per_class = []\n",
    "    for row in metrics['Acc_per_class'].T:\n",
    "        acc = np.sum(row!=0)/len(row)\n",
    "        Acc_per_class.append(acc)\n",
    "    metrics['Acc_per_class'] = Acc_per_class\n",
    "    return metrics\n",
    "\n",
    "get_eval_result(p, gt_map, gt_fix_map=None, gt_fix_points=None, gt_labels=None, p_labels=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sal_eval(model, test_img, gt_map, inp_size, mode='simple', blur=False,gt_labels=None):\n",
    "    # if test_img_base_path is specified, then preserves the original\n",
    "    # nested structure of the directory from which the stuff is pulled\n",
    "    metrics = {\"R2\":[],'RMSE':[],'CC':[],'CC (saliconeval)':[],'KL':[],'SIM':[],'Acc':[],'Acc_per_class':[]}\n",
    "    c=0\n",
    "    if blur:\n",
    "        print('BLURRING PREDICTIONS')\n",
    "        if 'blur' not in savedir:\n",
    "            savedir = savedir+'_blur'\n",
    "    else:\n",
    "        print('NOT BLURRING PREDICTIONS')\n",
    "    pre = []\n",
    "    cla = []\n",
    "    maps = []\n",
    "    for i in tqdm.tqdm(range(len(test_img))):\n",
    "        imfile = test_img[i]\n",
    "        heatmap = cv2.imread(gt_map[i], cv2.IMREAD_GRAYSCALE)\n",
    "        batch = 0\n",
    "        time = 0\n",
    "        map_idx = 0\n",
    "        gt_shape = Image.open(imfile).size[::-1]\n",
    "        img = preprocess_images([imfile], inp_size[0], inp_size[1])\n",
    "        preds = model.predict(img)\n",
    "        #print(preds[3].shape)\n",
    "        if mode == 'multistream_concat':\n",
    "            p = preds[time][batch][map_idx][:, :, 0]\n",
    "        elif mode == 'simple':\n",
    "        #Use first two lines when using our own model    \n",
    "            #p = preds[0][batch][:,:,0]\n",
    "            #classif = preds[1][0]\n",
    "            p = preds[0][batch][:,:,0]\n",
    "            classif = preds[3].reshape(6,)\n",
    "        elif mode == 'singlestream':\n",
    "            p = preds[0][batch][time][:,:,0]\n",
    "        else:\n",
    "            raise ValueError('Unknown mode')\n",
    "        # set zero_to_255 to True when using our own model\n",
    "        p = postprocess_predictions(p, heatmap.shape[0], heatmap.shape[1], blur, normalize=False, zero_to_255=False)\n",
    "        m = calculate_metrics(p, gt_map=heatmap, gt_fix_map=None, gt_fix_points=None, gt_labels=gt_labels[i], p_labels=classif)\n",
    "        for key in metrics:\n",
    "            if key in m:\n",
    "                metrics[key].append(m[key][0])\n",
    "    for key in metrics:\n",
    "        if key != 'Acc_per_class':\n",
    "            metrics[key] = np.mean(metrics[key])\n",
    "    Acc_per_class = np.array(metrics['Acc_per_class']).T\n",
    "    Acc_per_class = Acc_per_class[5]\n",
    "    acc = np.sum(Acc_per_class!=0)/len(Acc_per_class)\n",
    "    metrics['Acc_per_class'] = acc\n",
    "    return metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of your model (Imp1k, metrics to Table)\n",
    "model_UMSI = keras.models.load_model('/path/to/model.hdf5')\n",
    "sal_eval(model_UMSI, data_sal[3], data_sal[4], inp_size=(shape_r, shape_c), mode='simple', blur=False, gt_labels=gt_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
