{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "import cv2\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "import tqdm\n",
    "import math, random\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_loading import load_datasets_singleduration\n",
    "from util import get_model_by_name, create_losses\n",
    "\n",
    "from losses_keras2 import *\n",
    "from sal_imp_utilities import *\n",
    "from cb import InteractivePlot\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check GPU status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THESE IN \n",
    "bp = \"/path/to/your/Dataset/\"\n",
    "\n",
    "dataset_imp = \"imp1k\"\n",
    "dataset_sal = \"UMSI_SALICON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imp = load_datasets_singleduration(dataset_imp, bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sal = load_datasets_singleduration(dataset_sal, bp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_savedir = \"ckpt\"\n",
    "\n",
    "# FILL THESE IN: set training parameters\n",
    "# If you want to resume from previous training, set load_weights = True\n",
    "load_weights = False\n",
    "weightspath = \"./ckpt/weights.hdf5\"\n",
    "\n",
    "batch_size = \n",
    "init_lr = \n",
    "lr_reduce_by = \n",
    "reduce_at_epoch = \n",
    "n_epochs = \n",
    "\n",
    "opt = \n",
    "\n",
    "model_name = \"UMSI\"\n",
    "model_inp_size = (, )\n",
    "model_out_size = (, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = model_inp_size + (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model \n",
    "model_params = {\n",
    "    'input_shape': input_shape,\n",
    "    'n_outs': 2\n",
    "}\n",
    "model_func, mode = get_model_by_name(model_name)\n",
    "model = model_func(**model_params)\n",
    "\n",
    "if load_weights: \n",
    "    model.load_weights(weightspath)\n",
    "    print(\"load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data generation and checkpoints\n",
    "if not os.path.exists(ckpt_savedir): \n",
    "    os.makedirs(ckpt_savedir)\n",
    "\n",
    "# Generators\n",
    "gen_train = ImpAndClassifGenerator(\n",
    "        img_filenames=data_imp[0],\n",
    "        imp_filenames=data_imp[1],\n",
    "        fix_filenames=None,\n",
    "        extra_imgs=data_sal[0], # For feeding a much larger dataset, e.g. salicon, that the generator will subsample to maintain class balance\n",
    "        extra_imps=data_sal[1],\n",
    "        extra_fixs=None,\n",
    "        extras_per_epoch=160,\n",
    "        batch_size=4,\n",
    "        img_size=(shape_r,shape_c),\n",
    "        map_size=(shape_r_out, shape_c_out),\n",
    "        shuffle=True,\n",
    "        augment=False,\n",
    "        n_output_maps=1,\n",
    "        concat_fix_and_maps=False,\n",
    "        fix_as_mat=False,\n",
    "        fix_key=\"\",\n",
    "        str2label=None,\n",
    "        dummy_labels=False,\n",
    "        num_classes=6,\n",
    "        pad_imgs=True,\n",
    "        pad_maps=True,\n",
    "        return_names=False,\n",
    "        return_labels=True,\n",
    "        read_npy=False)\n",
    "\n",
    "gen_val = ImpAndClassifGenerator(\n",
    "            img_filenames=data_imp[3], \n",
    "            imp_filenames=data_imp[4], \n",
    "            fix_filenames=None, \n",
    "            extra_imgs=data_sal[3], # For feeding a much larger dataset, e.g. salicon, that the generator will subsample to maintain class balance\n",
    "            extra_imps=data_sal[4],\n",
    "            extra_fixs=None,\n",
    "            extras_per_epoch=40,\n",
    "            batch_size=1, \n",
    "            img_size=(shape_r,shape_c), \n",
    "            map_size=(shape_r_out, shape_c_out),\n",
    "            shuffle=False, \n",
    "            augment=False, \n",
    "            str2label=None,\n",
    "            dummy_labels=False,\n",
    "            #n_output_maps=1,\n",
    "        )\n",
    "\n",
    "# Callbacks\n",
    "\n",
    "# where to save checkpoints\n",
    "filepath = os.path.join(ckpt_savedir, dataset_imp + '_kl+cc+bin_ep{epoch:02d}_valloss{val_loss:.4f}.hdf5')\n",
    "\n",
    "print(\"Checkpoints will be saved with format %s\" % filepath)\n",
    "\n",
    "cb_chk = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=True, period=1)\n",
    "cb_plot = InteractivePlot()\n",
    "\n",
    "def step_decay(epoch):\n",
    "    lrate = init_lr * math.pow(lr_reduce_by, math.floor((1+epoch)/reduce_at_epoch))\n",
    "    if epoch%reduce_at_epoch:\n",
    "        print('Reducing lr. New lr is:', lrate)\n",
    "    return lrate\n",
    "cb_sched = LearningRateScheduler(step_decay)\n",
    "\n",
    "cbs = [cb_chk, cb_sched, cb_plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the generator \n",
    "img, outs = gen_train.__getitem__(1)\n",
    "print(\"batch size: %d. Num inputs: %d. Num outputs: %d.\" % (batch_size, len(img), len(outs)))\n",
    "print(outs[0].shape)\n",
    "print(outs[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss={'dec_c_cout': kl_cc_combined, \"out_classif\":\"binary_crossentropy\"}, loss_weights={'dec_c_cout': 1, \"out_classif\":5})\n",
    "\n",
    "print('Ready to train')\n",
    "model.fit_generator(gen_train, epochs=n_epochs, verbose=1, callbacks=cbs, validation_data=gen_val, max_queue_size=10, workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization scripts to check the training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: \n",
    "    W = \"./ckpt/weights.hdf5\"\n",
    "    model.load_weights(W)\n",
    "    print('load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize some output on the val set \n",
    "gen = UMSI_eval_generator(\n",
    "    data_sal[3], \n",
    "    data_sal[4], \n",
    "    inp_size=model_inp_size)\n",
    "\n",
    "examples = [next(gen) for _ in range(50)]\n",
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in examples[4:]:\n",
    "    images, maps, img_filename_= example\n",
    "    preds = model.predict(images[0])\n",
    "    preds_map = preds[0]\n",
    "    preds_classif = preds[1]\n",
    "    break\n",
    "\n",
    "\n",
    "print(\"maps size\", len(maps), maps[0].shape)\n",
    "batch = 0\n",
    "\n",
    "plt.figure(figsize = (14,8))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(reverse_preprocess(np.squeeze(images[0])))\n",
    "\n",
    "plt.title(\"natural images %d\" % batch)\n",
    "\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(maps[0])\n",
    "plt.title('Gt ' )\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(postprocess_predictions(np.squeeze(preds_map[0]),maps[0].shape[0],maps[0].shape[1], zero_to_255=True))\n",
    "plt.title('Prediction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, maps, img_filename= random.choice(examples)\n",
    "\n",
    "print(\"maps size\", len(maps), maps[0].shape)\n",
    "batch = 0\n",
    "preds = model.predict(images[0])\n",
    "preds_map = preds[0]\n",
    "preds_classif = preds[1]\n",
    "cl = np.argmax(preds_classif)\n",
    "print(preds_classif)\n",
    "plt.figure(figsize = (14,8))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(reverse_preprocess(np.squeeze(images[0])))\n",
    "if(cl==0):\n",
    "    plt.title(\"advertisment %d\" % batch)\n",
    "if(cl==1):\n",
    "    plt.title(\"infographic %d\" % batch)\n",
    "if(cl==2):\n",
    "    plt.title(\"movie_posters %d\" % batch)\n",
    "if(cl==3):\n",
    "    plt.title(\"infographics %d\" % batch)\n",
    "if(cl==4):\n",
    "    plt.title(\"webpages %d\" % batch)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(maps[0])\n",
    "plt.title('Gt ' )\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "    # print(\"preds time sahpe\", preds[time].shape)\n",
    "plt.imshow(postprocess_predictions(np.squeeze(preds_map[0]),maps[0].shape[0],maps[0].shape[1], zero_to_255=True))\n",
    "plt.title('Prediction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images, maps, img_filename= random.choice(examples)\n",
    "\n",
    "print(\"maps size\", len(maps), maps[0].shape)\n",
    "batch = 0\n",
    "preds = model.predict(images[0])\n",
    "preds_map = preds[0]\n",
    "preds_classif = preds[1]\n",
    "print(preds_classif)\n",
    "plt.figure(figsize = (14,8))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(reverse_preprocess(np.squeeze(images[0])))\n",
    "plt.title(\"original image %d\" % batch)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(maps[0])\n",
    "plt.title('Gt ' )\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "    # print(\"preds time sahpe\", preds[time].shape)\n",
    "plt.imshow(postprocess_predictions(np.squeeze(preds_map[0]),maps[0].shape[0],maps[0].shape[1], zero_to_255=True))\n",
    "plt.title('Prediction')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = \"./ckpt/imp1k_kl+cc+bin_ep13_valloss-2.4641.hdf5\"\n",
    "model.load_weights(W)\n",
    "print(\"load weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model, test_img, gt_map, inp_size, mode='simple', blur=False,):\n",
    "    # if test_img_base_path is specified, then preserves the original\n",
    "    # nested structure of the directory from which the stuff is pulled\n",
    "    c=0\n",
    "    if blur:\n",
    "        print('BLURRING PREDICTIONS')\n",
    "        if 'blur' not in savedir:\n",
    "            savedir = savedir+'_blur'\n",
    "    else:\n",
    "        print('NOT BLURRING PREDICTIONS')\n",
    "    pre = []\n",
    "    cla = []\n",
    "    maps = []\n",
    "    for i in tqdm.tqdm(range(len(test_img))):\n",
    "        imfile = test_img[i]\n",
    "        heatmap = cv2.imread(gt_map[i], cv2.IMREAD_GRAYSCALE)\n",
    "        batch = 0\n",
    "        time = 0\n",
    "        map_idx = 0\n",
    "        gt_shape = Image.open(imfile).size[::-1]\n",
    "        img = preprocess_images([imfile], inp_size[0], inp_size[1])\n",
    "        preds = model.predict(img)\n",
    "        if mode == 'multistream_concat':\n",
    "            p = preds[time][batch][map_idx][:, :, 0]\n",
    "        elif mode == 'simple':\n",
    "        #Use first two lines when using our own model    \n",
    "            p = preds[0][batch][:,:,0]\n",
    "            classif = preds[1][0]\n",
    "        elif mode == 'singlestream':\n",
    "            p = preds[0][batch][time][:,:,0]\n",
    "        else:\n",
    "            raise ValueError('Unknown mode')\n",
    "        # set zero_to_255 to True when using our own model\n",
    "        p = postprocess_predictions(p, heatmap.shape[0], heatmap.shape[1], blur, normalize=False, zero_to_255=True)\n",
    "        p_norm = (p-np.min(p))/(np.max(p)-np.min(p))\n",
    "        p_img = p_norm*255\n",
    "        hm_img = Image.fromarray(np.uint8(p_img), \"L\")\n",
    "        pre.append(p)\n",
    "        cla.append(classif)\n",
    "        maps.append(heatmap)\n",
    "    return np.array(pre), cla, maps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted maps, predicted classification labels, and the ground truth maps\n",
    "p, p_labels, gt_map = get_prediction(model, data_imp[3], data_imp[4], inp_size=(shape_r, shape_c), mode='simple', blur=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_labels = get_labels(data_sal[3])\n",
    "gt_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import calculate_metrics\n",
    "def get_eval_result(p, gt_map, gt_fix_map=None, gt_fix_points=None, gt_labels=None, p_labels=None):    \n",
    "    #metrics = {\"R2\":[],'RMSE':[],'CC':[],'CC (saliconeval)':[],'KL':[],'SIM':[],'Acc':[],'Acc_per_class':[]}\n",
    "    metrics = {\"R2\":[],'RMSE':[],'CC':[],'CC (saliconeval)':[],'KL':[],'SIM':[],}\n",
    "    for i in range(len(gt_map)):\n",
    "        m = calculate_metrics(p[i], gt_map=gt_map[i], gt_fix_map=None, gt_fix_points=None, gt_labels=None, p_labels=None)\n",
    "        for key in metrics:\n",
    "            if key in m:\n",
    "                metrics[key].append(m[key][0])\n",
    "    for key in metrics:\n",
    "        if key != 'Acc_per_class':\n",
    "            metrics[key] = np.mean(metrics[key])\n",
    "    Acc_per_class = []\n",
    "    for row in metrics['Acc_per_class'].T:\n",
    "        acc = np.sum(row!=0)/len(row)\n",
    "        Acc_per_class.append(acc)\n",
    "    metrics['Acc_per_class'] = Acc_per_class\n",
    "    return metrics\n",
    "\n",
    "get_eval_result(p, gt_map, gt_fix_map=None, gt_fix_points=None, gt_labels=None, p_labels=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sal_eval(model, test_img, gt_map, inp_size, mode='simple', blur=False,gt_labels=None):\n",
    "    # if test_img_base_path is specified, then preserves the original\n",
    "    # nested structure of the directory from which the stuff is pulled\n",
    "    metrics = {\"R2\":[],'RMSE':[],'CC':[],'CC (saliconeval)':[],'KL':[],'SIM':[],'Acc':[],'Acc_per_class':[]}\n",
    "    c=0\n",
    "    if blur:\n",
    "        print('BLURRING PREDICTIONS')\n",
    "        if 'blur' not in savedir:\n",
    "            savedir = savedir+'_blur'\n",
    "    else:\n",
    "        print('NOT BLURRING PREDICTIONS')\n",
    "    pre = []\n",
    "    cla = []\n",
    "    maps = []\n",
    "    for i in tqdm.tqdm(range(len(test_img))):\n",
    "        imfile = test_img[i]\n",
    "        heatmap = cv2.imread(gt_map[i], cv2.IMREAD_GRAYSCALE)\n",
    "        batch = 0\n",
    "        time = 0\n",
    "        map_idx = 0\n",
    "        gt_shape = Image.open(imfile).size[::-1]\n",
    "        img = preprocess_images([imfile], inp_size[0], inp_size[1])\n",
    "        preds = model.predict(img)\n",
    "        #print(preds[3].shape)\n",
    "        if mode == 'multistream_concat':\n",
    "            p = preds[time][batch][map_idx][:, :, 0]\n",
    "        elif mode == 'simple':\n",
    "        #Use first two lines when using our own model    \n",
    "            #p = preds[0][batch][:,:,0]\n",
    "            #classif = preds[1][0]\n",
    "            p = preds[0][batch][:,:,0]\n",
    "            classif = preds[3].reshape(6,)\n",
    "        elif mode == 'singlestream':\n",
    "            p = preds[0][batch][time][:,:,0]\n",
    "        else:\n",
    "            raise ValueError('Unknown mode')\n",
    "        # set zero_to_255 to True when using our own model\n",
    "        p = postprocess_predictions(p, heatmap.shape[0], heatmap.shape[1], blur, normalize=False, zero_to_255=False)\n",
    "        m = calculate_metrics(p, gt_map=heatmap, gt_fix_map=None, gt_fix_points=None, gt_labels=gt_labels[i], p_labels=classif)\n",
    "        for key in metrics:\n",
    "            if key in m:\n",
    "                metrics[key].append(m[key][0])\n",
    "    for key in metrics:\n",
    "        if key != 'Acc_per_class':\n",
    "            metrics[key] = np.mean(metrics[key])\n",
    "    Acc_per_class = np.array(metrics['Acc_per_class']).T\n",
    "    Acc_per_class = Acc_per_class[5]\n",
    "    acc = np.sum(Acc_per_class!=0)/len(Acc_per_class)\n",
    "    metrics['Acc_per_class'] = acc\n",
    "    return metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of your model (Imp1k, metrics to Table)\n",
    "model_UMSI = keras.models.load_model('/path/to/model.hdf5')\n",
    "sal_eval(model_UMSI, data_sal[3], data_sal[4], inp_size=(shape_r, shape_c), mode='simple', blur=False, gt_labels=gt_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
